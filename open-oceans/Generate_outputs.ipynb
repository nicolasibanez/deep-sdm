{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf471e06-f2f4-4cca-9cbc-054a0f1d9b3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = ['bathy-gebco', 'salinity3d', 'wave-height', 'surface-wind-u', 'surface-wind-v',\n",
    "          'oxygen', 'ph', 'fsle', 'fsle-orientation', 'geos-current-u',\n",
    "          'geos-current-v', 'eke', 'chlorophyll-occi', 'sst-mur', 'mixed-layer-thickness',\n",
    "          'diatoms', 'dinophytes', 'haptophytes', 'green-algae', 'prochlorophytes',\n",
    "          'prokaryotes', 'chlorophyll-occi-15', 'sst-mur-15', 'sst-mur-5', 'chlorophyll-occi-5',\n",
    "          'Atlantic', 'Indian', 'Pacific', 'North hemisphere']\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "from pathlib import Path\n",
    "import csv\n",
    "\n",
    "from hydra import compose, initialize\n",
    "from multi38 import predict, test, last_checkpoint, Multi38DataModule\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib widget\n",
    "\n",
    "natural_earth_path = Path(gpd.__file__).parent / 'datasets/naturalearth_lowres/naturalearth_lowres.shp'\n",
    "\n",
    "data_path = Path('../data/')\n",
    "\n",
    "# Indicate your checkpoint path and name here\n",
    "ckpt_path = Path(\"../outputs/multi38/\")\n",
    "ckpt_name = '2023-05-22_11-12-13/checkpoint-epoch=09--val_f1=0.6592.ckpt'\n",
    "ckpt_ref = ckpt_name.split('/')[0] + '_' \n",
    "\n",
    "initialize(config_path=ckpt_path / Path(ckpt_name).parent / 'logs/', version_base=\"1.1\")\n",
    "cfg = compose(config_name=\"hparams\")\n",
    "cfg.other.ckpt_name = ckpt_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb0a857-273c-4f6b-8ccf-236dce590b78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with (data_path / 'species.csv').open() as file:\n",
    "    species = [r[1] for r in csv.reader(file)][1:]\n",
    "\n",
    "with (data_path / 'species.csv').open() as file:\n",
    "    species_ids = [r[0] for r in csv.reader(file)][1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72990613-352c-4267-9ffb-681ccaf3b61c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Make predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b140ce59-ee6b-4590-b755-bbe3d22f9595",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "df = pd.read_csv(data_path / cfg.data.dataset_name, index_col = 'id')\n",
    "df = df.loc[df.index[df[\"subset\"] == 'test']].reset_index()\n",
    "df['geometry'] = df['geometry'].apply(wkt.loads)\n",
    "gdf = gpd.GeoDataFrame(df, crs='epsg:4326')\n",
    "\n",
    "groundtruth = np.array([species_ids.index(x) for x in list(df['species'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2b0612-c87d-4678-b4a3-427566f5e232",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Calculate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7905f450-5484-4235-9833-f50258340a17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_predictions = predict(cfg)\n",
    "predictions = np.argmax(all_predictions, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4865704f-2c63-4ca8-aaa4-2b4dc42fafaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 1 score\n",
    "\n",
    "(groundtruth == predictions).sum() / groundtruth.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a24f929-8ac9-46d3-8896-49f39c1eb04e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Top 10 Score\n",
    "\n",
    "for i in list(range(1, 11)) + [38]:\n",
    "    sec_ind = np.argpartition(all_predictions, -i, axis=1)[:,-i:]\n",
    "    prob = (np.expand_dims(groundtruth,axis=-1) == sec_ind).sum() / groundtruth.shape[0]\n",
    "    print(i, f\"{prob:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49e4daa-e002-4a25-9e39-b7065f517e85",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ef7e14-5670-49be-8ce9-87b2283dd831",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(groundtruth, predictions, labels=range(38), normalize = 'true')\n",
    "cm = cm.round(2)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 16))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=species)\n",
    "disp.plot(xticks_rotation = 'vertical', colorbar = False, text_kw={'fontsize': 'x-small'},ax=ax)\n",
    "plt.tight_layout()\n",
    "#plt.show()\n",
    "#plt.savefig(data_path / f\"../outputs/confusion_matrix/{ckpt_ref}cm.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c073c50b-14eb-422f-9539-d0c6416fa345",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Make predictions for new data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc15ef17-0df4-4fbf-bb38-6a23af646fd7",
   "metadata": {},
   "source": [
    "### World"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aca344f-9657-4a06-8328-69c0ca4f767b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cfg.data.dataset_name = \"datasets/world_tiled.csv\"\n",
    "all_predictions = predict(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11bf33a-d8d0-4e88-9826-a69472d4e9e4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### WIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daf82d7-e29d-49b0-93a4-1061ce3de8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.data.dataset_name = \"datasets/wio-tiled.csv\"\n",
    "all_predictions = predict(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7eb1ab-85f4-47b9-a833-93683e9541b2",
   "metadata": {},
   "source": [
    "### Export to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809b0c09-b25d-410e-80f6-5279bcd9e7da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path / cfg.data.dataset_name, index_col = 'id')\n",
    "\n",
    "results = pd.DataFrame(all_predictions, columns=species, index = df.index)\n",
    "full = df.merge(results, left_index=True, right_index=True)\n",
    "full['best-species'] = np.argmax(all_predictions,axis=1)\n",
    "full.to_csv(data_path / f\"../outputs/world-predictions/{ckpt_ref}world_predictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612354d8-f3f1-410e-8e4a-e0e3e4e519f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Export outputs to images or rasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4723d4-a219-44fe-bcf2-b23e28774051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from scipy.interpolate import griddata\n",
    "import rasterio\n",
    "import rasterio.mask\n",
    "import geopandas as gpd\n",
    "from rasterio.transform import from_origin\n",
    "from cftime import date2num\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde020b0-7351-45bc-a27b-b73efc39e46a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Geotiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914ebf04-0e15-49dc-a86f-779f2f479a30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_csv_path = data_path / f\"../outputs/wio-predictions/{ckpt_ref}wio_predictions.csv\"\n",
    "data_value_range = [0,1]\n",
    "map_bounds = [20, 80, -60, 0]\n",
    "res = 0.02\n",
    "folder = Path(f\"../outputs/wio-rasters/{ckpt_ref}rasters/\")\n",
    "\n",
    "# input_csv_path = data_path / f\"../outputs/world-predictions/{ckpt_ref}world_predictions.csv\"\n",
    "# data_value_range = [0,1]\n",
    "# map_bounds = [-180, 180, -90, 90]\n",
    "# res = 0.1\n",
    "# folder = Path(f\"../outputs/world-rasters/{ckpt_ref}rasters/\")\n",
    "\n",
    "full = pd.read_csv(input_csv_path, index_col = 'id')\n",
    "    \n",
    "\n",
    "if not(folder.exists()):\n",
    "    folder.mkdir()\n",
    "\n",
    "for s in tqdm(species):\n",
    "    \n",
    "    ref = s.replace(' ','_')\n",
    "    subfolder = folder / ref\n",
    "    if not(subfolder.exists()):\n",
    "        subfolder.mkdir()\n",
    "    \n",
    "    data_column_name = s\n",
    "    dates = list(full['date'].unique())\n",
    "    \n",
    "    for d in dates:\n",
    "\n",
    "        df = full[full['date'] == d]\n",
    "        output_raster_path = subfolder / f\"{ref}-{d}.tiff\"\n",
    "        \n",
    "        # Define output grid dimensions\n",
    "        lon_range, lat_range = map_bounds[1] - map_bounds[0], map_bounds[3] - map_bounds[2]\n",
    "        xs = np.linspace(0.5, lon_range / res - 0.5, int(lon_range / res))\n",
    "        ys = np.linspace(0.5, lat_range / res - 0.5, int(lat_range / res))\n",
    "        X, Y = np.meshgrid(xs, ys)\n",
    "\n",
    "        # Convert point data to grid coordinates\n",
    "        x = ((df['lon'] - map_bounds[0]) / res).to_numpy(dtype=int)\n",
    "        y = ((df['lat'] - map_bounds[2]) / res).to_numpy(dtype=int)\n",
    "        values = df[data_column_name].to_numpy()\n",
    "\n",
    "        # Interpolate to grid\n",
    "        band = griddata((x, y), values, (X, Y), method = 'cubic', fill_value = -1)\n",
    "\n",
    "        # Resample to 1-254 interval (0=nodata)\n",
    "        normed = (band - data_value_range[0]) / (data_value_range[1] - data_value_range[0])\n",
    "        data = np.floor(254*np.flip(np.clip([normed],0,1), axis=1))\n",
    "        data = data.astype(np.uint8) + 1\n",
    "\n",
    "        # Reproject to EPSG:4326 and save GeoTIFF\n",
    "        transform = from_origin(map_bounds[0], map_bounds[3], res, res)\n",
    "        dst = rasterio.open(output_raster_path, 'w', driver='GTiff',\n",
    "                            height = data.shape[1], width = data.shape[2],\n",
    "                            dtype=str(data.dtype),\n",
    "                            count=1,\n",
    "                            crs='epsg:4326',\n",
    "                            transform=transform,\n",
    "                            nodata=0,\n",
    "                            compress='lzw')\n",
    "\n",
    "        dst.write(data)\n",
    "        dst.close()\n",
    "\n",
    "        # Mask continents\n",
    "        continents = gpd.read_file(natural_earth_path).unary_union\n",
    "\n",
    "        with rasterio.open(output_raster_path, driver='GTiff') as src:\n",
    "            out_image, out_transform = rasterio.mask.mask(src, [continents], invert=True)\n",
    "\n",
    "        with rasterio.open(output_raster_path, 'r+', driver='GTiff') as dst:\n",
    "            dst.transform = out_transform\n",
    "            dst.write(out_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f09f6d8-e8a8-42b8-8ca7-79eff5c94385",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### PNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8a801f-ac8e-45d7-bf50-caeb138be1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export rasters as PNG\n",
    "\n",
    "import cv2\n",
    "from matplotlib import cm\n",
    "\n",
    "in_folder = Path(f\"../outputs/wio-rasters/{ckpt_ref}rasters/\")\n",
    "out_folder = Path(f\"../outputs/wio-png/{ckpt_ref}png/\")\n",
    "\n",
    "if not(out_folder.exists()):\n",
    "    out_folder.mkdir()\n",
    "\n",
    "for s in tqdm(species):\n",
    "    \n",
    "    ref = s.replace(' ','_')\n",
    "    in_subfolder = in_folder / ref\n",
    "    out_subfolder = out_folder / ref\n",
    "    \n",
    "    if not(out_subfolder.exists()):\n",
    "        out_subfolder.mkdir()\n",
    "    \n",
    "    for f in in_subfolder.glob('*.tiff'):\n",
    "\n",
    "        out_file = Path(out_subfolder, f.stem + '.png')\n",
    "\n",
    "        with rasterio.open(f, driver='GTiff') as src:\n",
    "            \n",
    "            data = src.read(1)\n",
    "            scaled = (np.float32(data) -1) / 254\n",
    "            scaled[scaled<0] = np.nan       \n",
    "          \n",
    "            im2 = getattr(cm, 'Blues')(scaled)\n",
    "            im2[np.isnan(scaled)] =  np.array([0,0,0,1])\n",
    "            im3 = cv2.cvtColor(np.float32(255*im2), cv2.COLOR_BGRA2RGBA)\n",
    "\n",
    "            ## Add date\n",
    "            h, w, _ = im3.shape\n",
    "            date_index = f.stem.find('2021')\n",
    "            date = f.stem[date_index:date_index+10]\n",
    "            im3 = cv2.putText(im3, date, (int(0.02*w), int(0.06*h)), fontFace = cv2.FONT_HERSHEY_SIMPLEX, fontScale=4, color=(255,255,255,255), thickness=10)\n",
    "            \n",
    "            cv2.imwrite(str(out_file), im3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418a065b-ab3e-43d9-bb3f-39f7f01f31bf",
   "metadata": {},
   "source": [
    "### Make gifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2605fc77-6e5f-4385-af6c-6447bbf5dad7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for s in tqdm(species):\n",
    "    ref = s.replace(' ','_')\n",
    "    !convert -resize 800x800 -delay 30 -loop 0 ../outputs/wio-png/{ckpt_ref}png/{ref}/*.png ../outputs/wio-gifs/{ckpt_ref}gifs/{ref}.gif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a602f1d-9c1f-4b44-be99-a6f92306b079",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Make figure for Prionace glauca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9270dd14-4b94-4e2c-b5bc-15b421184dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'Prionace glauca'\n",
    "ref = s.replace(' ','_')\n",
    "folder = Path(f\"../outputs/wio-png/{ckpt_ref}png\") / ref\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(5, 4, figsize = (16, 20))\n",
    "i = 0\n",
    "\n",
    "for f in sorted(folder.glob('*.png')):\n",
    "    if i % 3:\n",
    "        j = i // 3\n",
    "        ax = axes[j // 4, j % 4]\n",
    "        image = plt.imread(f)\n",
    "        ax.axis('off')\n",
    "        ax.imshow(image)\n",
    "    i += 1\n",
    "\n",
    "axes[4,2].axis('off')\n",
    "axes[4,3].axis('off')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig(Path(f\"../outputs/\") / \"WIO_prionace_grid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642901f1-09ce-4fe4-a0ee-4bce95c7adde",
   "metadata": {},
   "source": [
    "# Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afeff50d-5ab0-4689-8191-6762a84e4b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "from scipy import stats\n",
    "import torch\n",
    "from multi38 import *\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from random import sample\n",
    "import pickle\n",
    "\n",
    "from captum.attr import IntegratedGradients\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget\n",
    "\n",
    "meds, perc1, perc99 = np.load(data_path / \"stats.npy\")\n",
    "meds = np.expand_dims(np.expand_dims(meds,axis=-1),axis=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975a9d7f-acbf-47f2-ab4e-397a7697a86c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Calculate integrated gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a099f27-a7e0-4c95-9a6a-acd6fdcbd1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = cfg.other.ckpt_path + cfg.other.ckpt_name\n",
    "cfg.data.dataset_name = data_path.parent / f\"outputs/world-predictions/{ckpt_ref}world_predictions.csv\"\n",
    "cfg.data.inference_batch_size = 1\n",
    "\n",
    "model = ClassificationSystem.load_from_checkpoint(ckpt_path, model=cfg.model, **cfg.optimizer)\n",
    "model.eval()\n",
    "\n",
    "datamodule = Multi38DataModule(**cfg.data)\n",
    "datamodule.setup(stage='predict')\n",
    "ds = datamodule.get_dataset('test', datamodule.test_transform)\n",
    "ig = IntegratedGradients(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01d4c99-a5dd-4658-9920-1f3223b37a1b",
   "metadata": {},
   "source": [
    "## Over whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaf5aa9-a6a2-4064-91a5-91f84a164ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "full = pd.read_csv(data_path / f\"../outputs/world-predictions/{ckpt_ref}world_predictions.csv\", index_col = 'id')\n",
    "all_obs_ids = list(ds.observation_ids)\n",
    "\n",
    "out_folder = Path(f\"../outputs/interpretation/{ckpt_ref}/\")\n",
    "\n",
    "if not(out_folder.exists()):\n",
    "    out_folder.mkdir()\n",
    "\n",
    "glob_l = []\n",
    "    \n",
    "l = []\n",
    "for k in sample(range(len(all_obs_ids)), 1000):\n",
    "\n",
    "    # Calculate integrated gradient and average on the tile\n",
    "    x = ds[k][0]\n",
    "    x.requires_grad_()\n",
    "    target = int(full.loc[all_obs_ids[k], 'best-species'])\n",
    "    attr = ig.attribute(x.unsqueeze(0), target = target).detach().numpy().squeeze()\n",
    "    abs_attr = np.abs(attr)\n",
    "    averages = abs_attr.mean(axis=(1,2))\n",
    "    glob_l.append(averages)\n",
    "\n",
    "# Save statistics to csv file\n",
    "\n",
    "glob_table = np.vstack(glob_l)\n",
    "glob_df = pd.DataFrame(glob_table)\n",
    "glob_df.columns = labels\n",
    "glob_df.describe().T.to_csv(out_folder / \"All.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed90bed-70d0-4897-8ef2-55f2b4d607c8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## By species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f8e791-a5f9-4cb1-aa86-038ebbdc6ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from random import sample\n",
    "\n",
    "full = pd.read_csv(data_path / f\"../outputs/world-predictions/{ckpt_ref}world_predictions.csv\", index_col = 'id')\n",
    "all_obs_ids = list(ds.observation_ids)\n",
    "\n",
    "out_folder = Path(f\"../outputs/interpretation/{ckpt_ref}/\")\n",
    "\n",
    "if not(out_folder.exists()):\n",
    "    out_folder.mkdir()\n",
    "\n",
    "for i in tqdm(range(38)):\n",
    "    s = species[i]\n",
    "    subdf = full[full['best-species'] == i]\n",
    "    obs_ids = subdf.index\n",
    "    obs_ids_index = [all_obs_ids.index(obs_id) for obs_id in obs_ids]\n",
    "    \n",
    "    l = []\n",
    "    \n",
    "    for k in sample(obs_ids_index, min(1000,len(subdf))):\n",
    "\n",
    "        # Calculate integrated gradient and average on the tile\n",
    "        x = ds[k][0]\n",
    "        x.requires_grad_()\n",
    "        target = int(full.loc[all_obs_ids[k], 'best-species'])\n",
    "        attr = ig.attribute(x.unsqueeze(0), target = target).detach().numpy().squeeze()\n",
    "        abs_attr = np.abs(attr)\n",
    "        averages = abs_attr.mean(axis=(1,2))\n",
    "        l.append(averages)\n",
    "\n",
    "    \n",
    "    if len(l):\n",
    "\n",
    "        # Save statistics to csv files\n",
    "    \n",
    "        table = np.vstack(l)\n",
    "        df = pd.DataFrame(table)\n",
    "        df.columns  = labels\n",
    "        df.describe().T.to_csv(out_folder / f\"{s}.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141a2fe4-90f8-43d0-bcf9-3b9b23b7d2ae",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Plot results by species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b311d0d8-93ef-4f5b-a96f-e71fd9ce5c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['bathymetry', 'salinity', 'wave height', 'surface wind (u)', 'surface wind (v)',\n",
    "          'oxygen', 'pH', 'fsle (strength)', 'fsle (orientation)', 'geos current (u)',\n",
    "          'geos current (v)', 'chlorophyll', 'sea surface temperature', 'mixed layer thickness',\n",
    "          'diatoms', 'dinophytes', 'haptophytes', 'green algae', 'prochlorophytes',\n",
    "          'prokaryotes', 'Atlantic Ocean', 'Indian Ocean', 'Pacific Ocean', 'North hemisphere']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29748e8e-4a45-476d-a6e3-fc6d94034b10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Calculate top variables\n",
    "\n",
    "summa = pd.read_csv(f\"../outputs/interpretation/{ckpt_ref}/All.csv\", index_col = 0)\n",
    "topn = list(summa.sort_values('50%', ascending = False).index[:8])\n",
    "print(', '.join(topn))\n",
    "\n",
    "# Create chart\n",
    "\n",
    "series_dict = {}\n",
    "\n",
    "for i in range(38):\n",
    "    s = species[i]\n",
    "    p = Path(f\"../outputs/interpretation/{ckpt_ref}/{s}.csv\")\n",
    "    if p.exists():\n",
    "        df = pd.read_csv(p, index_col = 0)\n",
    "        series_dict[s] = df['50%']\n",
    "\n",
    "df = pd.concat(series_dict, axis = 1).T\n",
    "df.drop(columns = ['eke', 'chlorophyll-occi-15', 'sst-mur-15', 'sst-mur-5', 'chlorophyll-occi-5'], inplace = True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,12))\n",
    "sns.heatmap(df, ax = ax, cbar=False, cmap='YlOrRd')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb5f02b-e46b-46f9-9397-2d66431ef54d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Compare +2°C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddf5999-a264-4f6d-b12f-1af9c690eca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import cm\n",
    "\n",
    "in_folder0 = Path(f\"../outputs/world-rasters/{ckpt_ref}rasters/\")\n",
    "in_folder2 = Path(f\"../outputs/world-rasters+2/{ckpt_ref}rasters/\")\n",
    "out_folder = Path(f\"../outputs/world-png+2/{ckpt_ref}png/\")\n",
    "\n",
    "if not(out_folder.exists()):\n",
    "    out_folder.mkdir()\n",
    "\n",
    "for s in tqdm(species):\n",
    "    \n",
    "    ref = s.replace(' ','_')\n",
    "    in_subfolder0 = in_folder0 / ref\n",
    "    in_subfolder2 = in_folder2 / ref\n",
    "    out_subfolder = out_folder / ref\n",
    "    \n",
    "    if not(out_subfolder.exists()):\n",
    "        out_subfolder.mkdir()\n",
    "    \n",
    "    for f in in_subfolder0.glob('*.tiff'):\n",
    "\n",
    "        out_file = Path(out_subfolder, f.stem + '.png')\n",
    "\n",
    "        with rasterio.open(in_subfolder0 / f.name, driver='GTiff') as src0:\n",
    "            with rasterio.open(in_subfolder2 / f.name, driver='GTiff') as src2:       \n",
    "                data0 = np.float32(src0.read(1))\n",
    "                data2 = np.float32(src2.read(1))\n",
    "                \n",
    "                data0[data0==0] = np.nan  \n",
    "                data2[data2==0] = np.nan  \n",
    "\n",
    "                diff = (data2 - data0) / 253 + 0.5\n",
    "\n",
    "                im2 = getattr(cm, 'PiYG')(diff)\n",
    "                im2[np.isnan(diff)] =  np.array([0,0,0,1])\n",
    "                im3 = cv2.cvtColor(np.float32(255*im2), cv2.COLOR_BGRA2RGBA)\n",
    "            \n",
    "                cv2.imwrite(str(out_file), im3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
